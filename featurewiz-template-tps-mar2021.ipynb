{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This notebook got 0.8762 in one line of code (see below)\n##  Turn on the GPU Accelerator in this Notebook to get the fastest Results below using XGBoost"},{"metadata":{},"cell_type":"markdown","source":"## Goal: Use Featurwiz to build a better ranking model in TPS\n1.  Big_Mart Sales Prediction Score: 1147  -- Rank 250 out of 41,361 = That's a Top <1% Rank!!\n1.  Loan Status Predictions Score 0.791  -- Rank 850 out of 67,424 - Top 1.25% Rank\n1.  Machine Hack Flight Ticket Score 0.9389 -- Rank 165 out of 2723 - Top 6% Rank!\n1.  Machine Hack Data Scientist Salary class Score 0.417 -- Rank 58 out of 1547 - Top 3.7% Rank! (Autoviml Score was 0.329 -- less than 0.417 of Featurewiz+Simple even though an NLP problem!)\n1.  MCHACK Book Price NLP Score 0.7336 -- Rank 104 Autoviml NLP problem and should have done better"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.dates as md\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import host_subplot\nimport mpl_toolkits.axisartist as AA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.covariance import EllipticEnvelope\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Install Featurewiz Library to Get the Max Benefits"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install featurewiz","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from featurewiz import FE_kmeans_resampler, FE_find_and_cap_outliers, EDA_find_outliers\nfrom featurewiz import FE_convert_all_object_columns_to_numeric, split_data_n_ways, FE_create_categorical_feature_crosses\nfrom featurewiz import FE_create_time_series_features, FE_concatenate_multiple_columns\nfrom featurewiz import simple_XGBoost_model\nimport featurewiz as FW","execution_count":6,"outputs":[{"output_type":"stream","text":"Imported featurewiz: advanced feature engg and selection library. Version=0.0.31\noutput = featurewiz(dataname, target, corr_limit=0.70,\n                    verbose=2, sep=',', header=0, test_data='',\n                    feature_engg='', category_encoders='')\nCreate new features via 'feature_engg' flag : ['interactions','groupby','target']\n                                \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.max_columns', 500)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from load_kaggle import load_kaggle","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm, train, test = load_kaggle()\nprint(train.shape, test.shape)\ntrain.head(3)","execution_count":9,"outputs":[{"output_type":"stream","text":"submission found\ntrain found\ntest found\nfound 3 files and loaded them into dataframes. Please examine returned list for dataframes\n(300000, 32) (200000, 31)\n","name":"stdout"},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10 cat11 cat12  \\\n0   0    A    I    A    B    B   BI    A    S    Q    A    LO     A     A   \n1   1    A    I    A    A    E   BI    K    W   AD    F    HJ     A     B   \n2   2    A    K    A    A    E   BI    A    E   BM    L    DJ     A     B   \n\n  cat13 cat14 cat15 cat16 cat17 cat18  cont0  cont1  cont2  cont3  cont4  \\\n0     A     A     B     D     D     B  0.630  0.855  0.759  0.796  0.682   \n1     A     B     D     B     D     B  0.371  0.329  0.386  0.541  0.389   \n2     A     A     B     D     D     B  0.502  0.323  0.343  0.616  0.794   \n\n   cont5  cont6  cont7  cont8  cont9  cont10  target  \n0  0.622  0.592  0.792  0.815  0.965   0.666       0  \n1  0.358  0.600  0.409  0.399  0.927   0.494       0  \n2  0.553  0.352  0.389  0.412  0.293   0.549       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>cat9</th>\n      <th>cat10</th>\n      <th>cat11</th>\n      <th>cat12</th>\n      <th>cat13</th>\n      <th>cat14</th>\n      <th>cat15</th>\n      <th>cat16</th>\n      <th>cat17</th>\n      <th>cat18</th>\n      <th>cont0</th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>A</td>\n      <td>I</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>BI</td>\n      <td>A</td>\n      <td>S</td>\n      <td>Q</td>\n      <td>A</td>\n      <td>LO</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>D</td>\n      <td>B</td>\n      <td>0.630</td>\n      <td>0.855</td>\n      <td>0.759</td>\n      <td>0.796</td>\n      <td>0.682</td>\n      <td>0.622</td>\n      <td>0.592</td>\n      <td>0.792</td>\n      <td>0.815</td>\n      <td>0.965</td>\n      <td>0.666</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>A</td>\n      <td>I</td>\n      <td>A</td>\n      <td>A</td>\n      <td>E</td>\n      <td>BI</td>\n      <td>K</td>\n      <td>W</td>\n      <td>AD</td>\n      <td>F</td>\n      <td>HJ</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>B</td>\n      <td>D</td>\n      <td>B</td>\n      <td>0.371</td>\n      <td>0.329</td>\n      <td>0.386</td>\n      <td>0.541</td>\n      <td>0.389</td>\n      <td>0.358</td>\n      <td>0.600</td>\n      <td>0.409</td>\n      <td>0.399</td>\n      <td>0.927</td>\n      <td>0.494</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A</td>\n      <td>K</td>\n      <td>A</td>\n      <td>A</td>\n      <td>E</td>\n      <td>BI</td>\n      <td>A</td>\n      <td>E</td>\n      <td>BM</td>\n      <td>L</td>\n      <td>DJ</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>D</td>\n      <td>B</td>\n      <td>0.502</td>\n      <td>0.323</td>\n      <td>0.343</td>\n      <td>0.616</td>\n      <td>0.794</td>\n      <td>0.553</td>\n      <td>0.352</td>\n      <td>0.389</td>\n      <td>0.412</td>\n      <td>0.293</td>\n      <td>0.549</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Drop the following categorical vars according to the Blog Post here ###\n###     https://www.kaggle.com/c/tabular-playground-series-mar-2021/discussion/224530  #####  \ndrop_cols = ['cat5', 'cat7', 'cat8', 'cat10']\nprint(len(drop_cols))\ndrop_cols","execution_count":15,"outputs":[{"output_type":"stream","text":"4\n","name":"stdout"},{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"['cat5', 'cat7', 'cat8', 'cat10']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'target'\n#df[target] = (df[target] - np.mean(df[target]))/np.std(df[target])\n#train[target] = np.log(train[target].values)\nidcols = ['id']\nfeatures = [x for x in list(test) if x not in idcols+drop_cols]","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[features+[target]]\ndf = train.copy(deep=True)\nprint(train.shape)\ntrain.head(1)","execution_count":17,"outputs":[{"output_type":"stream","text":"(300000, 27)\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"  cat0 cat1 cat2 cat3 cat4 cat6 cat9 cat11 cat12 cat13 cat14 cat15 cat16  \\\n0    A    I    A    B    B    A    A     A     A     A     A     B     D   \n\n  cat17 cat18  cont0  cont1  cont2  cont3  cont4  cont5  cont6  cont7  cont8  \\\n0     D     B  0.630  0.855  0.759  0.796  0.682  0.622  0.592  0.792  0.815   \n\n   cont9  cont10  target  \n0  0.965   0.666       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat6</th>\n      <th>cat9</th>\n      <th>cat11</th>\n      <th>cat12</th>\n      <th>cat13</th>\n      <th>cat14</th>\n      <th>cat15</th>\n      <th>cat16</th>\n      <th>cat17</th>\n      <th>cat18</th>\n      <th>cont0</th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>I</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>D</td>\n      <td>B</td>\n      <td>0.630</td>\n      <td>0.855</td>\n      <td>0.759</td>\n      <td>0.796</td>\n      <td>0.682</td>\n      <td>0.622</td>\n      <td>0.592</td>\n      <td>0.792</td>\n      <td>0.815</td>\n      <td>0.965</td>\n      <td>0.666</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[target].hist()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test[features]\nprint(test.shape)\ntest.head(1)","execution_count":19,"outputs":[{"output_type":"stream","text":"(200000, 26)\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"  cat0 cat1 cat2 cat3 cat4 cat6 cat9 cat11 cat12 cat13 cat14 cat15 cat16  \\\n0    A    F    A    A    F    A    A     A     A     A     A     B     D   \n\n  cat17 cat18  cont0  cont1  cont2  cont3  cont4  cont5  cont6  cont7  cont8  \\\n0     D     B  0.708  0.736  0.578  0.723  0.228  0.356  0.551  0.656  0.598   \n\n   cont9  cont10  \n0  0.360   0.947  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat6</th>\n      <th>cat9</th>\n      <th>cat11</th>\n      <th>cat12</th>\n      <th>cat13</th>\n      <th>cat14</th>\n      <th>cat15</th>\n      <th>cat16</th>\n      <th>cat17</th>\n      <th>cat18</th>\n      <th>cont0</th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>D</td>\n      <td>B</td>\n      <td>0.708</td>\n      <td>0.736</td>\n      <td>0.578</td>\n      <td>0.723</td>\n      <td>0.228</td>\n      <td>0.356</td>\n      <td>0.551</td>\n      <td>0.656</td>\n      <td>0.598</td>\n      <td>0.360</td>\n      <td>0.947</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Just use this one line of code to get ~0.88 score in less than 2 mins!"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds,y_probas = simple_XGBoost_model(X_XGB=train[features], Y_XGB=train[target], X_XGB_test=test[features], \n                               modeltype='Classification', log_y=False,\n                               GPU_flag=True, scaler=StandardScaler(), enc_method='label', verbose=0)","execution_count":20,"outputs":[{"output_type":"stream","text":"Number of processors on machine = 2\nGPU available\n    Running XGBoost using GPU parameters\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"|          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4bbaacebf84cb8bf3aa364f4e39ad3"}},"metadata":{}},{"output_type":"stream","text":"Balanced Accuracy score in fold 1 = 77.3%\nBalanced Accuracy score in fold 2 = 76.8%\nBalanced Accuracy score in fold 3 = 77.5%\nBalanced Accuracy score in fold 4 = 77.5%\nBalanced Accuracy score in fold 5 = 77.5%\nBalanced Accuracy score in fold 6 = 77.1%\nBalanced Accuracy score in fold 7 = 77.4%\nBalanced Accuracy score in fold 8 = 77.1%\nBalanced Accuracy score in fold 9 = 77.1%\nBalanced Accuracy score in fold 10 = 77.4%\nAverage scores are:  0.7727118946445204\nfinal predictions [0 0 0 ... 0 0 0]\nsample of predicted probabilities [[0.79477656 0.20522346]\n [0.5947838  0.40521622]\n [0.92295337 0.07704666]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probas[:,1]","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"array([0.20522346, 0.40521622, 0.07704666, ..., 0.6769109 , 0.21496706,\n       0.23740548], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Base model above with no feature engg gets you ~0.88 score which is a very nice score.\nsubm[target] = y_probas[:,1]\nsubm.to_csv('submission.csv',index=False)\nsubm.head()","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"   id  target\n0   5   0.205\n1   6   0.405\n2   8   0.077\n3   9   0.223\n4  11   0.264","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>0.205</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>0.405</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>0.077</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0.223</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0.264</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Let's use Auto_ViML with GPU to see if we can do better"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install autoviml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from autoviml.Auto_ViML import Auto_ViML","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use AutoViz to gain some insights - here's what I understood\nimportant vars - leave them as is\ncont1\ncont3\ncont5\ncont6\ncont8\n\nbin the following:\ncont0 4\ncont1 5\ncont3 2\ncont4 2\ncont6 3\ncont8 3\ncont10 10\n\ngroupby vars\ncont3 by cat2\ncont1 by cat4\ncont3 by cat4\n\n\ninteraction cat vars - feature crosses\ncat4 x cat18\ncat13 x cat4\ncat13 x cat2\n\ninteraction vars and then bin them\ncont3 x cont7\ncont3 x cont8\ncont3 x cont9\ncont3 x cont10\ncont4 x cont5\ncont4 x cont6\ncont4 x cont9\ncont4 x cont10\n\nBoolean cats - leave them as is\ncat0\ncat1\ncat12\ncat13\ncat14\ncat15\ncat16\n\nlog transform these\ncont5\ncont8\ncont7\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install autoviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from autoviz.AutoViz_Class import AutoViz_Class\n#AV = AutoViz_Class()\n#filename = \"\"\n#sep = \",\"\n#dft = AV.AutoViz(\n#    filename,\n#    sep=\",\",\n#    depVar=target,\n#    dfte=train,\n#    header=0,\n#    verbose=0,\n#    lowess=False,\n#    chart_format=\"svg\",\n#    max_rows_analyzed=30000,\n#    max_cols_analyzed=30,\n#)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Feature Engineering using Featurewiz begins here using insights from AutoViz above"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Step 1: we create numeric interaction variables first ###\nintxn_vars = [('cont3', 'cont7'),('cont3', 'cont8'),('cont3', 'cont9'),('cont3', 'cont10'),('cont4', 'cont5'),\n             ('cont4', 'cont6'),('cont4', 'cont9'),('cont4', 'cont10')]\ndef FE_create_interaction_vars(df, intxn_vars):\n    \"\"\"\n    This handy function creates interaction variables among pairs of numeric vars you send in.\n    Your input must be a dataframe and a list of tuples. Each tuple must contain a pair of variables.\n    All variables must be numeric. Double check your input before sending them in.\n    \"\"\"\n    df = df.copy(deep=True)\n    for (each_intxn1,each_intxn2)  in intxn_vars:\n        new_col = each_intxn1 + '_x_' + each_intxn2\n        try:\n            df[new_col] = df[each_intxn1] * df[each_intxn2]\n        except:\n            continue\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = FE_create_interaction_vars(train, intxn_vars)\ntest = FE_create_interaction_vars(test, intxn_vars)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### we must bin the above newly created discrete variables into 4 or 6 buckets. We will choose 6 for now\nintx_cols = train.columns.tolist()[-8:]\nintx_dict = dict(zip(intx_cols, [6]*8))\ntrain, test = FW.FE_discretize_numeric_variables(train,intx_dict,test=test, strategy='gaussian')\nprint(train.shape, test.shape)\ntrain.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = [x for x in list(test) if x not in idcols]\nlen(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds,y_probas = simple_XGBoost_model(X_XGB=train[preds], Y_XGB=train[target], X_XGB_test=test[preds], \n                               modeltype='Classification', log_y=False,\n                               GPU_flag=True, scaler=StandardScaler(), enc_method='label', verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### The CV scores are less with new features. ####### So this is not worth adding these features\n### <Let us discard the new interaction variables and go back to the old train, test data > ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm, train, test = load_kaggle()\nprint(train.shape, test.shape)\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### step 2: we bin the following numeric variables using gaussian mixture models\nbin_these = {'cont0': 4, 'cont1': 5, 'cont3': 2, 'cont4': 2, 'cont6': 3, 'cont8': 3, 'cont10': 10}\ntrain, test = FW.FE_discretize_numeric_variables(train,bin_these,test=test, strategy='gaussian')\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = [x for x in list(test) if x not in idcols]\nlen(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds,y_probas = simple_XGBoost_model(X_XGB=train[preds], Y_XGB=train[target], X_XGB_test=test[preds], \n                               modeltype='Classification', log_y=False,\n                               GPU_flag=True, scaler=StandardScaler(), enc_method='label', verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### The CV scores are not bad - let's keep these binned variables and add to them in next steps ##","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### step 3: next we create feature crosses of these categorical variables ###\ntrain = FW.FE_create_categorical_feature_crosses(train, ['cat4','cat18','cat13','cat2'])\ntest = FW.FE_create_categorical_feature_crosses(test, ['cat4','cat18','cat13','cat2'])\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = [x for x in list(test) if x not in idcols]\nlen(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds,y_probas = simple_XGBoost_model(X_XGB=train[preds], Y_XGB=train[target], X_XGB_test=test[preds], \n                               modeltype='Classification', log_y=False,\n                               GPU_flag=True, scaler=StandardScaler(), enc_method='label', verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Absolutely no improvement - but we will keep these vars as long as performance is same! ####","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### step 4: create groupby aggregates of the following numerics \nagg_nums = ['cont1','cont3']\ngroupby_vars = ['cat2','cat4']\ntrain_add, test_add = FW.FE_add_groupby_features_aggregated_to_dataframe(train[agg_nums+groupby_vars], agg_types=['mean','std'],\n                                groupby_columns=groupby_vars,\n                                ignore_variables=[] , test=test[agg_nums+groupby_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_copy = train.join(train_add.drop(groupby_vars+agg_nums, axis=1))\ntest_copy = test.join(test_add.drop(groupby_vars+agg_nums, axis=1))\nprint(train_copy.shape, test_copy.shape)\ntrain_copy.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = [x for x in list(test_copy) if x not in idcols]\nlen(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds,y_probas = simple_XGBoost_model(X_XGB=train_copy[preds], Y_XGB=train[target], X_XGB_test=test_copy[preds], \n                               modeltype='Classification', log_y=False,\n                               GPU_flag=True, scaler=StandardScaler(), enc_method='label', verbose=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train,_ = FW.FE_split_one_field_into_many(train, field='Product', splitter='-', filler='missing')\ntest,_ = FW.FE_split_one_field_into_many(test, field='Product', splitter='-', filler='missing')\ntrain.head(1)"},{"metadata":{},"cell_type":"raw","source":"combs = ['Item_Category','Subcategory_1','Subcategory_2']\ntrain = FE_concatenate_multiple_columns(train, combs)\ntest = FE_concatenate_multiple_columns(test, combs)"},{"metadata":{},"cell_type":"markdown","source":"train = FE_find_and_cap_outliers(train,[target], verbose=1)\n#test = FE_find_and_cap_outliers(test,nums,verbose=0)"},{"metadata":{},"cell_type":"raw","source":"#output = split_data_n_ways(df,target, n_splits=2)"},{"metadata":{},"cell_type":"markdown","source":"train = FE_create_time_series_features(train, 'Date')\ntest = FE_create_time_series_features(test, 'Date')\ntrain.head(1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"###### step 5: log transform these columns ##########\nlog_cols = {'cont5':'log', 'cont8':'log', 'cont7':'log'}\ntrain_copy = FW.FE_transform_numeric_columns(train_copy, log_cols)\ntest_copy = FW.FE_transform_numeric_columns(test_copy, log_cols)\ntrain_copy.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### Lastly convert all object columns to numeric ############\ntrain_copy, test_copy = FE_convert_all_object_columns_to_numeric(train_copy,test_copy)\nprint(train_copy.shape, test_copy.shape)\ntrain_copy.head()"},{"metadata":{},"cell_type":"markdown","source":"# Select the best features created using Featurewiz"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_best, test_best = FW.featurewiz(train_copy, target, test_data=test_copy,verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def left_subtract(l1,l2):\n    lst = []\n    for i in l1:\n        if i not in l2:\n            lst.append(i)\n    return lst\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats = train_copy.select_dtypes(include=\"object\").columns.tolist()\nlen(cats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sel_nums = ['cont6', 'cont9', 'cont0_discrete', 'cont1_discrete', 'cont6_discrete', 'cont10_discrete', 'cont1_by_cat4_mean', 'cont1_by_cat4_std', 'cont3_by_cat4_mean', 'cont3_by_cat4_std', 'cont3_by_cat2_mean', 'cont1_by_cat2_std', 'cont5', 'cont8_discrete', 'cont1', 'cont4', 'cont3_discrete', 'cont10']\npreds = sel_nums+cats\nprint(len(preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### using reduced list of variables, the score actually drops 2% points! wow #######\ny_preds,y_probas = simple_XGBoost_model(X_XGB=train_copy[preds], Y_XGB=train[target], X_XGB_test=test_copy[preds], \n                               modeltype='Classification', log_y=False,\n                               GPU_flag=True, scaler=StandardScaler(), enc_method='label', verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####\nm, feats, trainm, testm = Auto_ViML(train_copy[preds+[target]], target, test_copy[preds],\n                            sample_submission='',\n                            scoring_parameter='', KMeans_Featurizer=False,\n                            hyper_param='RS',feature_reduction=True,\n                             Boosting_Flag=True, Binning_Flag=False,\n                            Add_Poly=0, Stacking_Flag=True,Imbalanced_Flag=False,\n                            verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds1 = testm['target_proba_1'].values\ny_preds1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm = test[idcols]\n#subm = pd.DataFrame()\nsubm[target] = y_preds1\nsubm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disto","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm.to_csv(target+'_Binary_Classification_submission2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Autoviml got about 0.8746 in the Kaggle rankings. #######\n###  This is slightly lower than 0.8845 that Autoviml got a month ago but it is about same as featurewiz\n### The good news is that AutoviML and Featurewiz now produce results on a 300K dataset lightning fast\n### It takes less than 2 mins for Autoviml and Featurewiz to crunch this dataset! That's a huge leap.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}